{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm5mqTlfieTY"
      },
      "source": [
        "#Load & inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CkZ8z1-dWsDz"
      },
      "outputs": [],
      "source": [
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRQtaIOuYG2e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_dir = \"MATH\"\n",
        "\n",
        "files = os.listdir(data_dir)\n",
        "print(\"Number of files:\", len(files))\n",
        "print(\"First 5 files:\", files[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mED52WxsZauS"
      },
      "outputs": [],
      "source": [
        "topic_dir = \"MATH/train/algebra\"\n",
        "algebra_files = os.listdir(topic_dir)\n",
        "\n",
        "print(\"Number of algebra questions:\", len(algebra_files))\n",
        "print(\"First 3 files:\", algebra_files[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTpr7khBZrIx"
      },
      "source": [
        "###inside json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii9Od2N1ZhvN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "sample_file = os.path.join(topic_dir, algebra_files[0])\n",
        "\n",
        "with open(sample_file, \"r\") as f:\n",
        "    sample_data = json.load(f)\n",
        "\n",
        "sample_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXOXfP45bgL6"
      },
      "source": [
        "###check - if all the subjects has the same configration (ex- problem,lvl,type etc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTufGu8DbFGQ"
      },
      "outputs": [],
      "source": [
        "topics = os.listdir(\"MATH/train\")\n",
        "\n",
        "for topic in topics[:3]:\n",
        "    topic_path = os.path.join(\"MATH/train\", topic)\n",
        "    file = os.listdir(topic_path)[0]\n",
        "    with open(os.path.join(topic_path, file)) as f:\n",
        "        print(topic, json.load(f).keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loWo1y9gcwIT"
      },
      "source": [
        "###Loading full training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE1nSD5Jc1uW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "train_dir = \"MATH/train\"\n",
        "\n",
        "for topic in os.listdir(train_dir):\n",
        "    topic_path = os.path.join(train_dir, topic)\n",
        "\n",
        "    if not os.path.isdir(topic_path):\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(topic_path):\n",
        "        file_path = os.path.join(topic_path, file)\n",
        "\n",
        "        with open(file_path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "            if \"problem\" in data:\n",
        "                texts.append(clean_text(data[\"problem\"]))\n",
        "                labels.append(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHDbixFbRkb5"
      },
      "source": [
        "####verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvRRaLx8RjDm"
      },
      "outputs": [],
      "source": [
        "print(len(texts), len(labels))\n",
        "from collections import Counter\n",
        "Counter(labels)\n",
        "print(texts[0])\n",
        "print(labels[0])\n",
        "set(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9sQK7jHh__z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = [len(t.split()) for t in texts]\n",
        "\n",
        "print(\"Total samples:\", len(texts))\n",
        "print(\"avg q length:\", np.mean(lengths))\n",
        "print(\"Max length:\", max(lengths))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g671EK7_iwxH"
      },
      "source": [
        "#preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB0WXE_ApXmv"
      },
      "outputs": [],
      "source": [
        "clean_texts = [clean_text(t) for t in texts]\n",
        "\n",
        "filtered_texts = []\n",
        "filtered_labels = []\n",
        "for t,l in zip(clean_texts,labels):  #zip creates pairs\n",
        "  filtered_texts.append(t)\n",
        "  filtered_labels.append(l)\n",
        "\n",
        "print(\"After filtering:\",len(filtered_texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BfMcybAP8zi"
      },
      "outputs": [],
      "source": [
        "set(filtered_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYDb0V9lqKi0"
      },
      "source": [
        "#vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPyXMAlaqNZA"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRSyCIgTr6Sw"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    lowercase=False,\n",
        "    stop_words=\"english\", #removes the,is,and ...\n",
        "    ngram_range=(1,2),\n",
        "    max_features=5000,\n",
        "    token_pattern=r'(?u)\\b[a-zA-Z][a-zA-Z]+\\b'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvL-jNPtZAO"
      },
      "source": [
        "###fit and transform the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C55_Dyv_temQ"
      },
      "outputs": [],
      "source": [
        "X = vectorizer.fit_transform(filtered_texts)\n",
        "print(\"TF-IDF shape:\", X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6muWhGMqvWmP"
      },
      "outputs": [],
      "source": [
        "#check\n",
        "#code extracts the top TF-IDF weighted words\n",
        "import numpy as np\n",
        "\n",
        "sample_vector = X[0].toarray()[0]\n",
        "top_indices = np.argsort(sample_vector)[-10:]\n",
        "\n",
        "top_words = vectorizer.get_feature_names_out()[top_indices]\n",
        "top_words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq_gNgw3PD_R"
      },
      "source": [
        "#LabelEncoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miV7IZN0PJEO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYe1gXa_PRV4"
      },
      "outputs": [],
      "source": [
        "#fitting\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(filtered_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EsJ8ZPgPiUF"
      },
      "outputs": [],
      "source": [
        "#label mapping\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(i, \"â†’\", label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArI6VqcDWD4T"
      },
      "source": [
        "#Train/Test/Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BocpErNHWCnH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y   #for non biased distribution in the testing data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZjriuO1X091"
      },
      "source": [
        "##training on logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-ZQZQ6uX5DN"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDVg2lsKdcIt"
      },
      "source": [
        "#evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVBnC8ZrdeUy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtMkuOVSfalo"
      },
      "source": [
        "####manual Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZnrY1K4ffEm"
      },
      "outputs": [],
      "source": [
        "sample_question = \"Find the derivative of x^2 + 3x + 1\"\n",
        "sample_vec = vectorizer.transform([clean_text(sample_question)])\n",
        "pred = model.predict(sample_vec)\n",
        "\n",
        "print(\"Predicted topic:\",\n",
        "      label_encoder.inverse_transform(pred)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pVFEpmahMr6"
      },
      "source": [
        "#LLM soln generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m59l-qOz5kzY"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baJC4SKb5uhf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrdX4lVn5vIR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",        # automatically use GPU\n",
        "    load_in_4bit=True,        # makes 7B fit on Colab\n",
        "    torch_dtype=torch.float16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UluGbMd54AT"
      },
      "outputs": [],
      "source": [
        "def build_prompt(question):\n",
        "    return f\"\"\"\n",
        "You are a high school mathematics teacher.\n",
        "Explain the following problem step by step in a clear and student-friendly way.\n",
        "\n",
        "Problem:\n",
        "{question}\n",
        "\n",
        "Solution:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj1VRIJM57A-"
      },
      "outputs": [],
      "source": [
        "def generate_solution_local(question):\n",
        "    prompt = build_prompt(question)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        temperature=0.3,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hsg18BZ5-Sl"
      },
      "outputs": [],
      "source": [
        "question = texts[0]   #check on small sample\n",
        "\n",
        "print(\"Question:\")\n",
        "print(question)\n",
        "\n",
        "print(\"\\nLLM Generated Explanation:\")\n",
        "print(generate_solution_local(question))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JHDbixFbRkb5"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}